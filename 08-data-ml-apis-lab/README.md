# Prepare Data for ML APIs on Google Cloud

**Duración:** 5 horas | **Puntos:** +21 pts | **Nivel:** Introductory

## Objetivos del lab
- Limpiar datos con Cloud Dataprep by Trifacta
- Crear pipelines de datos en Cloud Dataflow
- Configurar clusters y ejecutar jobs en Cloud Dataproc
- Usar Apache Spark para procesamiento distribuido
- Preparar datasets para Machine Learning

## Pasos del lab

### Preparación de datos
- [ ] Subir datasets raw a Cloud Storage
- [ ] Explorar calidad de datos
- [ ] Identificar transformaciones necesarias

### Procesamiento con Dataprep
- [ ] **Paso 1:** Conectar a fuentes de datos
- [ ] **Paso 2:** Crear recetas de transformación
- [ ] **Paso 3:** Limpiar y estructurar datos
- [ ] **Paso 4:** Validar transformaciones

### Pipeline con Dataflow/Dataproc
- [ ] **Paso 5:** Crear cluster de Dataproc
- [ ] **Paso 6:** Ejecutar jobs de Spark
- [ ] **Paso 7:** Procesar datos a gran escala
- [ ] **Paso 8:** Optimizar performance

### Preparación para ML
- [ ] Feature engineering
- [ ] Dividir train/validation/test sets
- [ ] Exportar datos procesados

## Recursos del lab
- Screenshots: `/recursos/screenshots/08-data-ml-apis/`
- Scripts PySpark: `/recursos/scripts/08-data-ml-apis/`
- Datasets: `/recursos/datasets/processed/`

## Progreso
- **Estado:** 📅 Pendiente
- **Completado:** 0%
- **Tiempo invertido:** 0h / 5h

## 📝 Mis notas

### Transformaciones aplicadas
```python
# Código de limpieza de datos
